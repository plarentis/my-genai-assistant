{
  "Comment": "GenAI Workflow that parallel validates prompt rules and execute RAG using Bedrock Agents KB",
  "StartAt": "Parallel",
  "States": {
    "Choice": {
      "Choices": [
        {
          "Variable": "$.ParallelInput[1].Body.content[0].text",
          "BooleanEquals": false,
          "Next": "Retrieve"
        }
      ],
      "Default": "GenerateResponse",
      "Type": "Choice"
    },
    "Parallel": {
      "Branches": [
        {
          "StartAt": "Insert Keywords",
          "Comment": "This state validate the user prompt and augment the content inserting keywords related to the topic. The KB will have more context",
          "States": {
            "Insert Keywords": {
              "End": true,
              "Parameters": {
                "Body": {
                  "anthropic_version": "bedrock-2023-05-31",
                  "max_tokens": 150,
                  "messages.$": "$.PromptInput[0, 1][*][*]",
                  "system.$": "$.claude_params.task_1.system",
                  "stop_sequences.$": "$.claude_params.task_1.stop_sequences",
                  "temperature": 0.7
                },
                "ModelId": "arn:aws:bedrock:${AWSRegion}::foundation-model/anthropic.claude-3-haiku-20240307-v1:0"
              },
              "Resource": "arn:aws:states:::bedrock:invokeModel",
              "Type": "Task"
            }
          }
        },
        {
          "StartAt": "KB Bypass Policy",
          "Comment": "Based on last KB data and context, validate if a new retrieve is necessary",
          "States": {
            "KB Bypass Policy": {
              "End": true,
              "Parameters": {
                "Body": {
                  "prompt.$": "States.Format('<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{}<|eot_id|><|start_header_id|>user<|end_header_id|>\n{}<|eot_id|><|start_header_id|)>assistant<end_header_id|>\n{}', $.claude_params.task_2.system, $.PromptInput[0].messages, $.PromptInput.[2].task_2[0].content)",
                  "temperature": 0.3,
                  "top_p": 0.5,
                  "max_gen_len": 50
                },
                "ModelId": "arn:aws:bedrock:${AWSRegion}::foundation-model/meta.llama3-8b-instruct-v1:0"
              },
              "Resource": "arn:aws:states:::bedrock:invokeModel",
              "Type": "Task",
              "ResultSelector": {
                "Body": {
                  "content": [
                    {
                      "text.$": "States.StringToJson($.Body.generation)"
                    }
                  ],
                  "model": "meta.llama3-8b-instruct-v1:0",
                  "usage": {
                    "input_tokens.$": "$.Body.prompt_token_count",
                    "output_tokens.$": "$.Body.generation_token_count"
                  }
                }
              }
            }
          }
        }
      ],
      "Next": "Choice",
      "ResultPath": "$.ParallelInput",
      "Type": "Parallel",
      "Parameters": {
        "claude_params": {
          "task_1": {
            "system": "",
            "stop_sequences": [
              "</keywords>"
            ]
          },
          "task_2": {
            "system": "You are a json object generator that follow the Rules: 1. Read the user/assistant JSON interaction history. 2. If the answer to the user's last query was clearly and detailed answered in the conversation history answer the \"{\"boolean\":true}\". 3. If the user's last query was not clearly and detailed answered, return the \"{\"boolean\":false}\". 4. use the json schema for boolean and answer with the json format \"{\"boolean\":{value}\". 5. For messages where the user intent is just a clear greeting like 'hello' or 'hi', answer \"{\"boolean\":true}\"",
            "stop_sequences": [
              "</boolean>"
            ]
          }
        },
        "PromptInput": [
          {
            "messages.$": "$.PromptInput"
          },
          {
            "task_1": [
              {
                "role": "assistant",
                "content": "<keywords>"
              }
            ]
          },
          {
            "task_2": [
              {
                "role": "assistant",
                "content": "{\"boolean\":"
              }
            ]
          }
        ]
      }
    },
    "Retrieve": {
      "Next": "GenerateResponseKb",
      "Parameters": {
        "KnowledgeBaseId": "${KnowledgeBaseId}",
        "RetrievalQuery": {
          "Text.$": "States.Format('{}, {}', States.ArrayGetItem($.PromptInput[-1:].content, 0), $.ParallelInput[0].Body.content[0].text)"
        }
      },
      "Resource": "arn:aws:states:::aws-sdk:bedrockagentruntime:retrieve",
      "ResultPath": "$.KnowledgeBaseData",
      "Type": "Task",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "GenerateResponseKBError",
          "ResultPath": "$.KnowledgeBaseData"
        }
      ],
      "ResultSelector": {
        "RetrievalResults.$": "$.RetrievalResults"
      }
    },
    "GenerateResponse": {
      "Comment": "Generates the Output Json for the caller",
      "End": true,
      "Type": "Pass",
      "Parameters": {
        "bedrock_details": {
          "task_details": [
            {
              "task_name": "task0",
              "task_model_id.$": "$.ParallelInput[0].Body.model",
              "input_token.$": "$.ParallelInput[0].Body.usage.input_tokens",
              "output_token.$": "$.ParallelInput[0].Body.usage.output_tokens"
            },
            {
              "task_name": "task1",
              "task_model_id.$": "$.ParallelInput[1].Body.model",
              "input_token.$": "$.ParallelInput[1].Body.usage.input_tokens",
              "output_token.$": "$.ParallelInput[1].Body.usage.output_tokens"
            }
          ],
          "total_input_tokens.$": "States.MathAdd($.ParallelInput[0].Body.usage.input_tokens, $.ParallelInput[1].Body.usage.input_tokens)",
          "total_output_tokens.$": "States.MathAdd($.ParallelInput[0].Body.usage.output_tokens, $.ParallelInput[1].Body.usage.output_tokens)"
        },
        "context_data": [],
        "system_chain_data": {
          "system_chain_prompt": "No Data generated this time, this is likely due to a greeting, repeated user's query or the answer is already provided in the conversation history. Check carefully and do not invent any information. You can answer user greetings in a friendly way.",
          "operation": "REPLACE_TAG",
          "configuration": {
            "replace_tag": "chain-information"
          }
        }
      }
    },
    "GenerateResponseKb": {
      "Comment": "Generates the Output Json for the caller",
      "Type": "Pass",
      "Parameters": {
        "bedrock_details": {
          "task_details": [
            {
              "task_name": "task0",
              "task_model_id.$": "$.ParallelInput[0].Body.model",
              "input_token.$": "$.ParallelInput[0].Body.usage.input_tokens",
              "output_token.$": "$.ParallelInput[0].Body.usage.output_tokens"
            },
            {
              "task_name": "task1",
              "task_model_id.$": "$.ParallelInput[1].Body.model",
              "input_token.$": "$.ParallelInput[1].Body.usage.input_tokens",
              "output_token.$": "$.ParallelInput[1].Body.usage.output_tokens"
            }
          ],
          "total_input_tokens.$": "States.MathAdd($.ParallelInput[0].Body.usage.input_tokens, $.ParallelInput[1].Body.usage.input_tokens)",
          "total_output_tokens.$": "States.MathAdd($.ParallelInput[0].Body.usage.output_tokens, $.ParallelInput[1].Body.usage.output_tokens)"
        },
        "context_data.$": "$.KnowledgeBaseData.RetrievalResults"
      },
      "End": true
    },
    "GenerateResponseKBError": {
      "Comment": "Generates the Output Json for KB error ",
      "End": true,
      "Type": "Pass",
      "Parameters": {
        "bedrock_details": {
          "task_details": [
            {
              "task_name": "task0",
              "task_model_id.$": "$.ParallelInput[0].Body.model",
              "input_token.$": "$.ParallelInput[0].Body.usage.input_tokens",
              "output_token.$": "$.ParallelInput[0].Body.usage.output_tokens"
            },
            {
              "task_name": "task1",
              "task_model_id.$": "$.ParallelInput[1].Body.model",
              "input_token.$": "$.ParallelInput[1].Body.usage.input_tokens",
              "output_token.$": "$.ParallelInput[1].Body.usage.output_tokens"
            }
          ],
          "total_input_tokens.$": "States.MathAdd($.ParallelInput[0].Body.usage.input_tokens, $.ParallelInput[1].Body.usage.input_tokens)",
          "total_output_tokens.$": "States.MathAdd($.ParallelInput[0].Body.usage.output_tokens, $.ParallelInput[1].Body.usage.output_tokens)"
        },
        "context_data": [
          {
            "Error.$": "$.KnowledgeBaseData.Error",
            "Cause.$": "$.KnowledgeBaseData.Cause",
            "Text": "Did you created the Bedrock KB? Check the URL: https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-create.html"
          }
        ],
        "system_chain_data": {
          "system_chain_prompt": "You are an error handler task. Your rules are: 1. Inform that you are a error handler task. 2. Inform the user you can't answer any question. 3. explain the bedrock error in the document tag.",
          "operation": "REPLACE_ALL"
        }
      }
    }
  }
}